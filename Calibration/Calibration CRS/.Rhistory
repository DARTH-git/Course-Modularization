v_params_test <- c(p_Mets = 0.10, p_DieMets = 0.05)
run_crs_markov(v_params_test) # It works!
# Specify seed (for reproducible sequence of random numbers)
set.seed(072218)
# number of random samples
n_samp <- 1000
# names and number of input parameters to be calibrated
v_param_names <- c("p_Mets","p_DieMets")
n_param <- length(v_param_names)
# range on input search space
lb <- c(p_Mets = 0.04, p_DieMets = 0.04) # lower bound
ub <- c(p_Mets = 0.16, p_DieMets = 0.16) # upper bound
# number of calibration targets
v_target_names <- c("Surv")
n_target <- length(v_target_names)
# record start time of calibration
t_init <- Sys.time()
###  Generate a random sample of input values  ###
# Sample unit Latin Hypercube
m_lhs_unit <- randomLHS(n_samp, n_param)
# Rescale to min/max of each parameter
m_param_samp <- matrix(nrow=n_samp,ncol=n_param)
for (i in 1:n_param){
m_param_samp[,i] <- qunif(m_lhs_unit[,i],
min = lb[i],
max = ub[i])
}
colnames(m_param_samp) <- v_param_names
# view resulting parameter set samples
pairs.panels(m_param_samp)
###  Run the model for each set of input values ###
# initialize goodness-of-fit vector
m_GOF <- matrix(nrow = n_samp, ncol = n_target)
colnames(m_GOF) <- paste0(v_target_names, "_fit")
# loop through sampled sets of input values
for (j in 1:n_samp){
###  Run model for a given parameter set  ###
model_res <- run_crs_markov(v_params = m_param_samp[j, ])
###  Calculate goodness-of-fit of model outputs to targets  ###
# TARGET 1: Survival ("Surv")
# log likelihood
m_GOF[j,1] <- sum(dnorm(x = lst_targets$Surv$value,
mean = model_res$Surv,
sd = lst_targets$Surv$se,
log = T))
# weighted sum of squared errors (alternative to log likelihood)
# w <- 1/(lst_targets$Surv$se^2)
# m_GOF[j,1] <- -sum(w*(lst_targets$Surv$value - v_res)^2)
# TARGET 2: (if you had more...)
# log likelihood
# m_GOF[j,2] <- sum(dnorm(x = lst_targets$Target2$value,
#                        mean = model_res$Target2,
#                        sd = lst_targets$Target2$se,
#                        log = T))
} # End loop over sampled parameter sets
###  Combine fits to the different targets into single GOF  ###
# can give different targets different weights
v_weights <- matrix(1, nrow = n_target, ncol = 1)
# matrix multiplication to calculate weight sum of each GOF matrix row
v_GOF_overall <- c(m_GOF%*%v_weights)
# Store in GOF matrix with column name "Overall"
m_GOF <- cbind(m_GOF,Overall_fit=v_GOF_overall)
# Calculate computation time
comp_time <- Sys.time() - t_init
# Arrange parameter sets in order of fit
m_calib_res <- cbind(m_param_samp,m_GOF)
m_calib_res <- m_calib_res[order(-m_calib_res[,"Overall_fit"]),]
# Examine the top 10 best-fitting sets
m_calib_res[1:10,]
# Plot the top 100 (top 10%)
plot(m_calib_res[1:100,1],m_calib_res[1:100,2],
xlim=c(lb[1],ub[1]),ylim=c(lb[2],ub[2]),
xlab = colnames(m_calib_res)[1],ylab = colnames(m_calib_res)[2])
# Pairwise comparison of top 100 sets
pairs.panels(m_calib_res[1:100,v_param_names])
### Plot model-predicted output at best set vs targets ###
v_out_best <- run_crs_markov(m_calib_res[1,])
# TARGET 1: Survival ("Surv")
plotrix::plotCI(x = lst_targets$Surv$time, y = lst_targets$Surv$value,
ui = lst_targets$Surv$ub,
li = lst_targets$Surv$lb,
ylim = c(0, 1),
xlab = "Time", ylab = "Pr Survive")
points(x = lst_targets$Surv$time,
y = v_out_best$Surv,
pch = 8, col = "red")
legend("topright",
legend = c("Target", "Model-predicted output"),
col = c("black", "red"), pch = c(1, 8))
# TARGET 2: (if you had more...)
# plotrix::plotCI(x = lst_targets$Target2$time, y = lst_targets$Target2$value,
#                 ui = lst_targets$Target2$ub,
#                 li = lst_targets$Target2$lb,
#                 ylim = c(0, 1),
#                 xlab = "Time", ylab = "Target 2")
# points(x = lst_targets$Target2$time,
#        y = v_out_best$Target2,
#        pch = 8, col = "red")
# legend("topright",
#        legend = c("Target", "Model-predicted output"),
#        col = c("black", "red"), pch = c(1, 8))
rm(list = ls())      # clear memory (removes all the variables from the workspace)
if (!require('pacman')) install.packages('pacman'); library(pacman) # use this package to conveniently install other packages
# load (install if required) packages from CRAN
p_load("lhs", "plotrix", "psych")
load("CRS_CalibTargets.RData")
lst_targets <- CRS_targets
# Plot the targets
# TARGET 1: Survival ("Surv")
plotrix::plotCI(x = lst_targets$Surv$time, y = lst_targets$Surv$value,
ui = lst_targets$Surv$ub,
li = lst_targets$Surv$lb,
ylim = c(0, 1),
xlab = "Time", ylab = "Pr Survive")
# TARGET 2: (if you had more...)
# plotrix::plotCI(x = lst_targets$Target2$time, y = lst_targets$Target2$value,
#                 ui = lst_targets$Target2$ub,
#                 li = lst_targets$Target2$lb,
#                 ylim = c(0, 1),
#                 xlab = "Time", ylab = "Target 2")
# - inputs are parameters to be estimated through calibration
# - outputs correspond to the target data
source("CRS_MarkovModel_Function.R") # creates the function run_crs_markov()
# Check that it works
v_params_test <- c(p_Mets = 0.10, p_DieMets = 0.05)
run_crs_markov(v_params_test) # It works!
# Specify seed (for reproducible sequence of random numbers)
set.seed(072218)
# number of initial starting points
n_init <- 100
# names and number of input parameters to be calibrated
v_param_names <- c("p_Mets","p_DieMets")
n_param <- length(v_param_names)
# range on input search space
lb <- c(p_Mets = 0.04, p_DieMets = 0.04) # lower bound
ub <- c(p_Mets = 0.16, p_DieMets = 0.16) # upper bound
# number of calibration targets
v_target_names <- c("Surv")
n_target <- length(v_target_names)
# Write goodness-of-fit function to pass to Nelder-Mead algorithm
f_gof <- function(v_params){
# Run model for parametr set "v_params"
model_res <- run_crs_markov(v_params)
# Calculate goodness-of-fit of model outputs to targets
v_GOF <- numeric(n_target)
# TARGET 1: Survival ("Surv")
# log likelihood
v_GOF[1] <- sum(dnorm(x = lst_targets$Surv$value,
mean = model_res$Surv,
sd = lst_targets$Surv$se,
log = T))
# TARGET 2: (if you had more...)
# log likelihood
# v_GOF[2] <- sum(dnorm(x = lst_targets$Target2$value,
#                        mean = model_res$Target2,
#                        sd = lst_targets$Target2$se,
#                        log = T))
# OVERALL
# can give different targets different weights
v_weights <- rep(1,n_target)
# weighted sum
GOF_overall <- sum(v_GOF[1:n_target] * v_weights)
# return GOF
return(GOF_overall)
}
# record start time of calibration
t_init <- Sys.time()
###  Sample multiple random starting values for Nelder-Mead  ###
v_params_init <- matrix(nrow=n_init, ncol=n_param)
for (i in 1:n_param){
v_params_init[,i] <- runif(n_init,min=lb[i],max=ub[i])
}
colnames(v_params_init) <- v_param_names
###  Run Nelder-Mead for each starting point  ###
m_calib_res <- matrix(nrow = n_init, ncol = n_param+1)
colnames(m_calib_res) <- c(v_param_names, "Overall_fit")
for (j in 1:n_init){
### use optim() as Nelder-Mead ###
fit_nm <- optim(v_params_init[j,], f_gof,
control = list(fnscale = -1, # switches from minimization to maximization
maxit = 1000), hessian = T)
m_calib_res[j,] <- c(fit_nm$par,fit_nm$value)
### to use a simulated annealing instead ###
# fit_sa <- optim(v_params_init[j,], f_gof,
#                method = c("SANN"),  # switches to using simulated annealing
#                control = list(temp = 10, tmax = 10, # algorithm tuning parameters
#                               fnscale = -1, maxit = 1000),
#                hessian = T)
# m_calib_res[j,] = c(fit_sa$par,fit_sa$value)
### to use a genetic algorithm instead ###
# library(DEoptim)
# f_fitness <- function(params){
#   names(params) = v_param_names
#   return(-f_gof(params))}
# fit_ga = DEoptim(f_fitness, lower=lb, upper=ub)
# m_calib_res[j,] = c(fit_ga$optim$bestmem,-1*fit_ga$optim$bestval)
}
# Calculate computation time
comp_time <- Sys.time() - t_init
# Arrange parameter sets in order of fit
m_calib_res <- m_calib_res[order(-m_calib_res[,"Overall_fit"]),]
# Examine the top 10 best-fitting sets
m_calib_res[1:10, ]
# Plot the top 10 (top 10%)
plot(m_calib_res[1:10,1],m_calib_res[1:10,2],
xlim=c(lb[1],ub[1]),ylim=c(lb[2],ub[2]),
xlab = colnames(m_calib_res)[1],ylab = colnames(m_calib_res)[2])
# Pairwise comparison of top 10 sets
pairs.panels(m_calib_res[1:10,v_param_names])
### Plot model-predicted output at mean vs targets ###
v_out_best <- run_crs_markov(m_calib_res[1,])
# TARGET 1: Survival ("Surv")
plotrix::plotCI(x = lst_targets$Surv$time, y = lst_targets$Surv$value,
ui = lst_targets$Surv$ub,
li = lst_targets$Surv$lb,
ylim = c(0, 1),
xlab = "Time", ylab = "Pr Survive")
points(x = lst_targets$Surv$time,
y = v_out_best$Surv,
pch = 8, col = "red")
legend("topright",
legend = c("Target", "Model-predicted output"),
col = c("black", "red"), pch = c(1, 8))
# TARGET 2: (if you had more...)
# plotrix::plotCI(x = lst_targets$Target2$time, y = lst_targets$Target2$value,
#                 ui = lst_targets$Target2$ub,
#                 li = lst_targets$Target2$lb,
#                 ylim = c(0, 1),
#                 xlab = "Time", ylab = "Target 2")
# points(x = lst_targets$Target2$time,
#        y = v_out_best$Target2,
#        pch = 8, col = "red")
# legend("topright",
#        legend = c("Target", "Model-predicted output"),
#        col = c("black", "red"), pch = c(1, 8))
source("CRS_MarkovModel_Function.R") # creates the function run_crs_markov()
source("CRS_MarkovModel_Function.R") # creates the function run_crs_markov()
source("CRS_MarkovModel_Function.R") # creates the function run_crs_markov()
rm(list = ls())      # clear memory (removes all the variables from the workspace)
if (!require('pacman')) install.packages('pacman'); library(pacman) # use this package to conveniently install other packages
# load (install if required) packages from CRAN
p_load("lhs", "IMIS", "matrixStats", "plotrix", "psych")
load("CRS_CalibTargets.RData")
lst_targets <- CRS_targets
# Plot the targets
# TARGET 1: Survival ("Surv")
plotrix::plotCI(x = lst_targets$Surv$time, y = lst_targets$Surv$value,
ui = lst_targets$Surv$ub,
li = lst_targets$Surv$lb,
ylim = c(0, 1),
xlab = "Time", ylab = "Pr Survive")
# TARGET 2: (if you had more...)
# plotrix::plotCI(x = lst_targets$Target2$time, y = lst_targets$Target2$value,
#                 ui = lst_targets$Target2$ub,
#                 li = lst_targets$Target2$lb,
#                 ylim = c(0, 1),
#                 xlab = "Time", ylab = "Target 2")
# - inputs are parameters to be estimated through calibration
# - outputs correspond to the target data
source("CRS_MarkovModel_Function.R") # creates the function run_crs_markov()
# Check that it works
v_params_test <- c(p_Mets = 0.10, p_DieMets = 0.05)
run_crs_markov(v_params_test) # It works!
# Specify seed (for reproducible sequence of random numbers)
set.seed(072218)
# number of random samples
n_resamp <- 1000
# names and number of input parameters to be calibrated
v_param_names <- c("p_Mets","p_DieMets")
n_param <- length(v_param_names)
# range on input search space
lb <- c(p_Mets = 0.04, p_DieMets = 0.04) # lower bound
ub <- c(p_Mets = 0.16, p_DieMets = 0.16) # upper bound
# number of calibration targets
v_target_names <- c("Surv")
n_target       <- length(v_target_names)
#  Write function to sample from prior
sample_prior <- function(n_samp){
m_lhs_unit   <- randomLHS(n = n_samp, k = n_param)
m_param_samp <- matrix(nrow = n_samp, ncol = n_param)
colnames(m_param_samp) <- v_param_names
for (i in 1:n_param){
m_param_samp[, i] <- qunif(m_lhs_unit[,i],
min = lb[i],
max = ub[i])
# ALTERNATIVE prior using beta (or other) distributions
# m_param_samp[, i] <- qbeta(m_lhs_unit[,i],
#                            shape1 = 1,
#                            shape2 = 1)
}
return(m_param_samp)
}
# view resulting parameter set samples
pairs.panels(sample_prior(1000))
###  PRIOR  ###
# Write functions to evaluate log-prior and prior
# function that calculates the log-prior
calc_log_prior <- function(v_params){
if(is.null(dim(v_params))) { # If vector, change to matrix
v_params <- t(v_params)
}
n_samp <- nrow(v_params)
colnames(v_params) <- v_param_names
lprior <- rep(0, n_samp)
for (i in 1:n_param){
lprior <- lprior + dunif(v_params[, i],
min = lb[i],
max = ub[i],
log = T)
# ALTERNATIVE prior using beta distributions
# lprior <- lprior + dbeta(v_params[, i],
#                          shape1 = 1,
#                          shape2 = 1,
#                          log = T)
}
return(lprior)
}
calc_log_prior(v_params = v_params_test)
calc_log_prior(v_params = sample_prior(10))
# function that calculates the (non-log) prior
calc_prior <- function(v_params) {
exp(calc_log_prior(v_params))
}
calc_prior(v_params = v_params_test)
calc_prior(v_params = sample_prior(10))
###  LIKELIHOOD  ###
# Write functions to evaluate log-likelihood and likelihood
# function to calculate the log-likelihood
calc_log_lik <- function(v_params){
# par_vector: a vector (or matrix) of model parameters
if(is.null(dim(v_params))) { # If vector, change to matrix
v_params <- t(v_params)
}
n_samp <- nrow(v_params)
v_llik <- matrix(0, nrow = n_samp, ncol = n_target)
llik_overall <- numeric(n_samp)
for(j in 1:n_samp) { # j=1
jj <- tryCatch( {
###   Run model for parametr set "v_params" ###
model_res <- run_crs_markov(v_params[j, ])
###  Calculate log-likelihood of model outputs to targets  ###
# TARGET 1: Survival ("Surv")
# log likelihood
v_llik[j, 1] <- sum(dnorm(x = lst_targets$Surv$value,
mean = model_res$Surv,
sd = lst_targets$Surv$se,
log = T))
# TARGET 2: (if you had more...)
# log likelihood
# v_llik[j, 2] <- sum(dnorm(x = lst_targets$Target2$value,
#                        mean = model_res$Target2,
#                        sd = lst_targets$Target2$se,
#                        log = T))
# OVERALL
llik_overall[j] <- sum(v_llik[j, ])
}, error = function(e) NA)
if(is.na(jj)) { llik_overall <- -Inf }
} # End loop over sampled parameter sets
# return LLIK
return(llik_overall)
}
calc_log_lik(v_params = v_params_test)
calc_log_lik(v_params = sample_prior(10))
# function to calculate the (non-log) likelihood
calc_likelihood <- function(v_params){
exp(calc_log_lik(v_params))
}
calc_likelihood(v_params = v_params_test)
calc_likelihood(v_params = sample_prior(10))
###  POSTERIOR  ###
# Write functions to evaluate log-posterior and posterior
# function that calculates the log-posterior
calc_log_post <- function(v_params) {
lpost <- calc_log_prior(v_params) + calc_log_lik(v_params)
return(lpost)
}
calc_log_post(v_params = v_params_test)
calc_log_post(v_params = sample_prior(10))
# function that calculates the (non-log) posterior
calc_post <- function(v_params) {
exp(calc_log_post(v_params))
}
calc_post(v_params = v_params_test)
calc_post(v_params = sample_prior(10))
# record start time of calibration
t_init <- Sys.time()
###  Bayesian calibration using IMIS  ###
# define three functions needed by IMIS: prior(x), likelihood(x), sample.prior(n)
prior <- calc_prior
likelihood <- calc_likelihood
sample.prior <- sample_prior
# run IMIS
fit_imis <- IMIS(B = 1000, # the incremental sample size at each iteration of IMIS
B.re = n_resamp, # the desired posterior sample size
number_k = 10, # the maximum number of iterations in IMIS
D = 0)
# obtain draws from posterior
m_calib_res <- fit_imis$resample
# Calculate log-likelihood (overall fit) and posterior probability of each sample
m_calib_res <- cbind(m_calib_res,
"Overall_fit" = calc_log_lik(m_calib_res[,v_param_names]),
"Posterior_prob" = calc_post(m_calib_res[,v_param_names]))
# normalize posterior probability
m_calib_res[,"Posterior_prob"] <- m_calib_res[,"Posterior_prob"]/sum(m_calib_res[,"Posterior_prob"])
# Calculate computation time
comp_time <- Sys.time() - t_init
# Plot the 1000 draws from the posterior
v_post_color <- scales::rescale(m_calib_res[, "Posterior_prob"])
plot(m_calib_res,
xlim = c(lb[1], ub[1]), ylim = c(lb[2], ub[2]),
xlab = v_param_names[1], ylab = v_param_names[2],
col = scales::alpha("black", v_post_color))
# add center of Gaussian components
points(fit_imis$center, col = "red", pch = 8)
legend("topright", c("Draws from posterior", "Center of Gaussian components"),
col = c("black", "red"), pch = c(1, 8))
# Plot the 1000 draws from the posterior with marginal histograms
pairs.panels(m_calib_res[,v_param_names])
# Compute posterior mean
v_calib_post_mean <- colMeans(m_calib_res[,v_param_names])
v_calib_post_mean
# Compute posterior median and 95% credible interval
m_calib_res_95cr <- colQuantiles(m_calib_res[,v_param_names], probs = c(0.025, 0.5, 0.975))
m_calib_res_95cr
# Compute maximum-a-posteriori (MAP) parameter set
v_calib_map <- m_calib_res[which.max(m_calib_res[,"Posterior_prob"]),]
### Model-predicted output at mode/MAP ###
v_out_best <- run_crs_markov(v_calib_map[v_param_names])
### Plot model-predicted output at mode vs targets ###
# set plot margins (helps plotting)
par(mar=c(5,4,4,4))
# TARGET 1: Survival ("Surv")
plotrix::plotCI(x = lst_targets$Surv$time, y = lst_targets$Surv$value,
ui = lst_targets$Surv$ub,
li = lst_targets$Surv$lb,
ylim = c(0, 1),
xlab = "Time", ylab = "Pr Survive")
points(x = lst_targets$Surv$time,
y = v_out_best$Surv,
pch = 8, col = "red")
legend("topright",
legend = c("Target", "Model-predicted output"),
col = c("black", "red"), pch = c(1, 8))
# TARGET 2: (if you had more...)
# plotrix::plotCI(x = lst_targets$Target2$time, y = lst_targets$Target2$value,
#                 ui = lst_targets$Target2$ub,
#                 li = lst_targets$Target2$lb,
#                 ylim = c(0, 1),
#                 xlab = "Time", ylab = "Target 2")
# points(x = lst_targets$Target2$time,
#        y = v_out_best$Target2,
#        pch = 8, col = "red")
# legend("topright",
#        legend = c("Target", "Model-predicted output"),
#        col = c("black", "red"), pch = c(1, 8))
### Distribution of model-predicted output at mode vs targets ###
## Initialize matrix to store outputs
m_out_post <- matrix(NA,
nrow = n_resamp,
ncol = length(v_out_best$Surv))
## Iterate model over all parameter sets from posterior distribution
for(i in 1:n_resamp){
l_out <- run_crs_markov(m_calib_res[i, ])
m_out_post[i, ] <- l_out$Surv
if(i/(n_resamp/10) == round(i/(n_resamp/10),0)) { # display progress every 10%
cat('\r', paste(i/n_resamp * 100, "% done", sep = " "))
}
}
## Compute model-predicted posterior summary statistics
# Model-predicted posterior mean
v_out_post_mean      <- colMeans(m_out_post)
# Model-predicted posterior credible interval
m_out_post_intervals <- colQuantiles(m_out_post, probs = c(0.025, 0.975))
# set plot margins (helps plotting)
par(mar=c(5,4,4,4))
# TARGET 1: Survival ("Surv")
plotrix::plotCI(x = lst_targets$Surv$time, y = lst_targets$Surv$value,
ui = lst_targets$Surv$ub,
li = lst_targets$Surv$lb,
ylim = c(0, 1),
xlab = "Time", ylab = "Pr Survive")
points(x = lst_targets$Surv$time,
y = v_out_post_mean,
pch = 8, col = "red")
lines(x = lst_targets$Surv$time,
y = m_out_post_intervals[, 1],
col = "blue")
lines(x = lst_targets$Surv$time,
y = m_out_post_intervals[, 2],
col = "blue")
legend("topright",
legend = c("Target",
"Model-predicted posterior mean",
"Model-predicted 95% posterior CrI"),
col = c("black", "red", "blue"),
pch = c(1, 8, NA),
lty = c(NA, NA, 1))
# TARGET 2: (if you had more...)
# plotrix::plotCI(x = lst_targets$Target2$time, y = lst_targets$Target2$value,
#                 ui = lst_targets$Target2$ub,
#                 li = lst_targets$Target2$lb,
#                 ylim = c(0, 1),
#                 xlab = "Time", ylab = "Target 2")
# points(x = lst_targets$Target2$time,
#        y = v_out_best$Target2,
#        pch = 8, col = "red")
# legend("topright",
#        legend = c("Target", "Model-predicted output"),
#        col = c("black", "red"), pch = c(1, 8))
[Download demo](../../../rmds/Markov_3state_SA.Rmd)
blogdown:::serve_site()
## Demo
