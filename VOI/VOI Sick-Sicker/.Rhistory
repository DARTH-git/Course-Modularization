## Discount rate
disc <- c(0.03)
# Technology lifetime
LT   <- 10
time <- seq(0, LT)
## Per Annum Number of Individuals to Be Treated With Urate Lowering Therapy
# Present prevalence
prev     <- 0.010 # In millions(1e6)
# Annual Incidence.
incid    <- 147*1e-6 # In millions: 0.005*29.376e-3
## Total population afectd by technology calculated with `TotPop` function in Millions
tot.pop <- TotPop(time,    # Function
prev,
incid,
disc)
## Population EVPSI
# Obervational study
pop.evsi.obs <- evsi.obs
pop.evsi.obs$popEVSI <- pop.evsi.obs$EVSI*tot.pop
# RCT
pop.evsi.rct <- evsi.rct
pop.evsi.rct$popEVSI <- pop.evsi.rct$EVSI*tot.pop
### Cost of research
## Obervational study
cost.res.obs <- CostRes(fixed.cost = 10000e-6,
samp.size = n.obs,  # vector
cost.per.patient = 500e-6, # In Million $
INMB = 0,
clin.trial = FALSE)
# Data frame with cost of trial in Millions
cost.obs <- data.frame(N = n.obs, CS = cost.res.obs)
## RCT
cost.res.rct <- CostRes(fixed.cost = 8000000e-6,
samp.size = n.rct,  # vector
cost.per.patient = 8500e-6, # In Million $
INMB = 0,
clin.trial = TRUE)
# Data frame with cost of trial in Millions
cost.rct <- data.frame(N = n.rct, CS = cost.res.rct)
### Create ENBS data frame
enbs.obs <- merge(pop.evsi.obs, cost.obs, by = "N")
enbs.rct <- merge(pop.evsi.rct, cost.rct, by = "N")
## Compute ENBS
enbs.obs$ENBS <- enbs.obs$popEVSI - enbs.obs$CS
enbs.rct$ENBS <- enbs.rct$popEVSI - enbs.rct$CS
## Compute OSS (n*)
enbs.obs$nstar <- enbs.obs$N[which.max(enbs.obs$ENBS)]
enbs.rct$nstar <- enbs.rct$N[which.max(enbs.rct$ENBS)]
# Append data frames
enbs.all <- rbind(enbs.obs,
enbs.rct)
require(dplyr)
#require(plyr)
oss <- summarise(group_by(enbs.all, Study),
MaxENBS = max(ENBS),
Nstar   = N[which.max(ENBS)])
## Plot ENBS, EVPSI and n*
# Create suitable data frames for plotting
enbs.obs.gg <- melt(enbs.obs[, -3], id.vars = c("Study", "N", "nstar"), value.name = "Million")
enbs.rct.gg <- melt(enbs.rct[, -3], id.vars = c("Study", "N", "nstar"), value.name = "Million")
# Append data frames for plotting
enbs.all.gg <- rbind(enbs.obs.gg,
enbs.rct.gg)
levels(enbs.all.gg$Study) <- c(paste("Observational; n* = ", comma(oss$Nstar[1]), sep=""),
paste("RCT; n* = ", comma(oss$Nstar[2]), sep=""))
ggplot(enbs.all.gg, aes(x = N, y = Million, colour = variable, group = variable)) +
facet_wrap(~ Study, scales = "free_x") +
#geom_segment(data = oss, aes(x = Nstar, y = 0, xend = Nstar, yend = MaxENBS)) +
geom_hline(aes(yintercept=0), size = 0.7, linetype = 2, colour = "gray") +
geom_vline(aes(xintercept = nstar), size = 0.7, linetype = 2, colour = "gray") +
geom_point() +
geom_line() +
scale_x_continuous(breaks = number_ticks(6), labels = comma)+
scale_y_continuous(breaks = number_ticks(6), labels = comma, limits = c(0, 40))+
scale_colour_hue("Study design ", l=50,
labels=c("popEVPSI(n) ", "Cost of Research(n) ", "ENBS(n) ")) +
xlab("Sample size (N)") +
ylab("Value (Million $)") +
theme_bw(base_size = 14) +
theme(legend.position = "bottom",
panel.margin = unit(2, "lines"))
# ggsave("Figs/Toy_ENBS.pdf", width = 8, height = 6)
# ggsave("Figs/Toy_ENBS.png", width = 8, height = 6)
#### Opimal Sample Size (OSS), n*
oss
rm(list = ls())      # clear memory (removes all the variables from the workspace)
if (!require('matrixStats')) install.packages('matrixStats'); library(matrixStats)
if (!require('ggplot2'))     install_github('ggplot2');       library(ggplot2)
if (!require('scales'))      install.packages('scales');      library(scales)
if (!require('grid'))        install.packages('grid');        library(grid)
if (!require('dplyr'))       install.packages('dplyr');       library(dplyr)
if (!require('reshape2'))    install.packages('reshape2');    library(reshape2)
if (!require('mgcv'))        install.packages('mgcv');        library(mgcv)
if (!require('gridExtra'))   install.packages('gridExtra');   library(gridExtra)
if (!require('gdata'))       install.packages('gdata');       library(gdata)
if (!require('devtools'))    install.packages('devtools');    library(devtools)
if (!require('dampack'))     install_github('DARTH-git/dampack'); library(dampack)
source("VOI_Functions.R")
source("GA_functions.R")
# Load simulation file
# Read the `.csv` simulation file into `R`.
toy   <- read.csv("PSA.csv", header = TRUE)[, -1]
n_sim <- nrow(toy)
# Display first five observations of the data fram using the command `head`
head(toy)
# Net Monetary Benefit (NMB)
# Create NMB matrix
nmb <- toy[, 5:7]
head(nmb)
# Number of Strategies
n_strategies <- ncol(nmb)
n_strategies
# Assign name of strategies
strategies    <- c("Strategy A", "Strategy B", "Strategy C")
colnames(nmb) <- strategies
head(nmb)
# Format data frame suitably for plotting
nmb_gg <- melt(nmb,
variable.name = "Strategy",
value.name = "NMB")
# Plot NMB for different strategies
# Faceted plot by Strategy
ggplot(nmb_gg, aes(x = NMB/1000)) +
geom_histogram(aes(y =..density..), col="black", fill = "gray") +
geom_density(color = "red") +
facet_wrap(~ Strategy, scales = "free_y") +
xlab("Net Monetary Benefit (NMB) x10^3") +
scale_x_continuous(breaks = number_ticks(5), labels = dollar) +
scale_y_continuous(breaks = number_ticks(5)) +
theme_bw()
# Calculate INMB of B vs A
# Only B vs A but we could have plotted all combinations
inmb <- data.frame(Simulation = 1:n_sim,
`Strategy B vs Strategy A` = nmb$`Strategy B` - nmb$`Strategy A`)
## Format data frame suitably for plotting
inmb_gg <- melt(inmb, id.vars = "Simulation",
variable.name = "Comparison",
value.name = "INMB")
txtsize<-16
## Plot INMB
ggplot(inmb_gg, aes(x = INMB/1000)) +
geom_histogram(aes(y =..density..), col="black", fill = "gray") +
geom_density(color = "red") +
geom_vline(xintercept = 0, col = 4, size = 1.5, linetype = "dashed") +
facet_wrap(~ Comparison, scales = "free_y") +
xlab("Incremental Net Monetary Benefit (INMB) in thousand $") +
scale_x_continuous(breaks = number_ticks(5), limits = c(-100, 100)) +
scale_y_continuous(breaks = number_ticks(5)) +
theme_bw(base_size = 14)
# Find optimal strategy (d*) based on the highest expected NMB
d_star <- which.max(colMeans(nmb))
d_star
# Compute Loss matrix iterating over all strategies
# Initialize loss matrix of dimension: number of simulation by number of strategies
loss <- matrix(0, n_sim, n_strategies)
for (d in 1:n_strategies){ # d <- 1
loss[, d] <- nmb[, d] - nmb[, d_star]
}
head(loss)
# Or without iterating (much faster!)
loss <- as.matrix(nmb - nmb[, d_star])
head(loss)
# Find maximum loss overall strategies at each state of the world
# (i.e., PSA sample)
max_loss_i <- rowMaxs(loss)
head(max_loss_i)
## Average across all states of the world
evpi <- mean(max_loss_i)
evpi
names_params <- c("Mean No. Visits (A)",
"Mean No. Visits (B)",
"Prob. Failing (A)",
"Prob. Failing (B)")
# Matrix with parameters
x <- toy[, 1:4]
colnames(x) <- names_params
head(x)
# Number and names of parameters
n_params <- ncol(x)
n_params
### Histogram of parameters
# Format data suitably for plotting
params <- melt(x, variable.name = "Parameter")
head(params)
# Make parameter names as factors (helps with plotting formatting)
params$Parameter <- factor(params$Parameter,
levels = names_params,
labels = names_params)
# Facet plot of parameter distributions
ggplot(params, aes(x = value)) +
geom_histogram(aes(y =..density..), col="black", fill = "gray") +
geom_density(color = "red") +
facet_wrap(~ Parameter, scales = "free") +
scale_x_continuous(breaks = number_ticks(5)) +
scale_y_continuous(breaks = number_ticks(5)) +
theme_bw(base_size = 14)
# Splines
# Initialize EVPPI vector
evppi_splines <- matrix(0, n_params)
lmm1 <- vector("list", n_params)
lmm2 <- vector("list", n_params)
lmm3 <- vector("list", n_params)
for (p in 1:n_params){ # p <- 1
print(paste("Computing EVPPI of parameter", names_params[p]))
# Estimate Splines
lmm1[[p]] <- gam(loss[, 1] ~ s(x[, p]))
lmm2[[p]] <- gam(loss[, 2] ~ s(x[, p]))
lmm3[[p]] <- gam(loss[, 2] ~ s(x[, p]))
# Predict Loss using Splines
Lhat_splines <- cbind(lmm1[[p]]$fitted, lmm2[[p]]$fitted, lmm3[[p]]$fitted)
# Compute EVPPI
evppi_splines[p] <- mean(rowMaxs(Lhat_splines))
}
### Ploting EVPPI using of order polynomial
evppi_splines_gg <- data.frame(Parameter = names_params, EVPPI = evppi_splines)
evppi_splines_gg$Parameter <- factor((evppi_splines_gg$Parameter),
levels = names_params[order(evppi_splines_gg$EVPPI, decreasing = TRUE)])
# Plot EVPPI using ggplot2 package
ggplot(data = evppi_splines_gg, aes(x = Parameter, y = EVPPI)) +
geom_bar(stat = "identity") +
ylab("EVPPI ($)") +
scale_y_continuous(breaks = number_ticks(6), labels = comma) +
theme_bw(base_size = 14)
# Effective (prior) Sample size
n0 <- c(10, # MeanNumVisitsA
10, # MeanNumVisitsB
10, # ProbFailA
10) # ProbFailB
n <- c(0, 1, 5, 10, seq(20, 200, by = 20))
n_samples <- length(n)
### Each parameter individually (only assuming linear relationship)
# Initialize EVSI matrix for each parameters
evsi <- data_frame(N = n, matrix(0, nrow = n_samples, ncol = n_params))
# Name columns of EVPSI matrix with parameter names
colnames(evsi)[-1] <- names_params
# Compute EVSI for all parameters separately
for (p in 1:n_params){ # p <- 1
print(paste("Computing EVSI of parameter", names_params[p]))
# Update loss based on gaussian approximation for each sample of interest
for (nSamp in 1:n_samples){ # nSamp <- 10
Ltilde1 <- predict.ga(lmm1[[p]], n = n[nSamp], n0 = n0[p])
Ltilde2 <- predict.ga(lmm2[[p]], n = n[nSamp], n0 = n0[p])
Ltilde3 <- predict.ga(lmm3[[p]], n = n[nSamp], n0 = n0[p])
## Combine losses into one matrix
Ltilde <- cbind(Ltilde1, Ltilde2, Ltilde3)
### Apply EVSI equation
evsi[nSamp, p+1] <- mean(rowMaxs(Ltilde))
}
}
# Plotting EVSI
# Create EVSI data frame for plotting in decreasing order of EVPPI
evsi_gg <- melt(evsi[1:21,], id.vars = "N",
variable.name = "Parameter",
value.name = "evsi")
# Plotting EVSI
# Create EVSI data frame for plotting in decreasing order of EVPPI
evsi_gg <- melt(evsi[1:21,], id.vars = "N",
variable.name = "Parameter",
value.name = "evsi")
for (p in 1:n_params){ # p <- 1
print(paste("Computing EVSI of parameter", names_params[p]))
# Update loss based on gaussian approximation for each sample of interest
for (nSamp in 1:n_samples){ # nSamp <- 10
Ltilde1 <- predict.ga(lmm1[[p]], n = n[nSamp], n0 = n0[p])
Ltilde2 <- predict.ga(lmm2[[p]], n = n[nSamp], n0 = n0[p])
Ltilde3 <- predict.ga(lmm3[[p]], n = n[nSamp], n0 = n0[p])
## Combine losses into one matrix
Ltilde <- cbind(Ltilde1, Ltilde2, Ltilde3)
### Apply EVSI equation
evsi[nSamp, p+1] <- mean(rowMaxs(Ltilde))
}
}
# Plotting EVSI
# Create EVSI data frame for plotting in decreasing order of EVPPI
evsi_gg <- melt(evsi[1:21,], id.vars = "N",
variable.name = "Parameter",
value.name = "evsi")
EVSI
evsi
setwd("C:/Users/Alan Yang/Google Drive/DARTH/Courses/2019 Washington - Choice/VOI_students/R_code")
# title: "Value of Information Analysis using Regression Metamodeling"
# subtitle: ESMDM 2018 Short Course, June 10th, Leiden, The Netherlands.
# author: "Hawre Jalal & Fernando Alarid-Escudero"
## Clean everythng from workspace
rm(list=ls())
## Install Packages (If you haven't done so yet!)
# install.packages("gdata")
# install.packages("xlsx")
# install.packages("ggplot2")
# install.packages("reshape2")
# install.packages("scales")
# install.packages("grid")
# install.packages("gridExtra")
# install.packages("dplyr")
# install.packages("matrixStats")
library(matrixStats)
library(ggplot2)
library(scales)  # For dollar labels
library(grid)
library(reshape2)
library(mgcv) # For fitting splines
## Set working space
#Define work directory
# #Mac OS X
#setwd("/Users/")
#Windows
#setwd("c:\\VOI_Course")
#### Load VOI Functions ####
source("VOI_Functions.R")
source("GA_functions.R")
#### Simple Example: WTP = $50,000/QALY ####
## Load simulation file
# Read the `.csv` simulation file into `R`.
toy <- read.csv("PSA.csv", header = TRUE)[, -1]
n.sim <- nrow(toy)
#Display first five observations of the data fram using the command `head`
head(toy)
### Net Monetary Benefit (NMB) ####
# Create NMB matrix
nmb <- toy[, 5:7]
head(nmb)
# Number of Strategies
n.strategies <- ncol(nmb)
n.strategies
# Assign name of strategies
strategies <- c("Strategy A", "Strategy B", "Strategy C")
colnames(nmb) <- strategies
head(nmb)
## Format data frame suitably for plotting
nmb.gg <- melt(nmb,
variable.name = "Strategy",
value.name = "NMB")
## Plot NMB for different strategies
# Faceted plot by Strategy
ggplot(nmb.gg, aes(x = NMB/1000)) +
geom_histogram(aes(y =..density..), col="black", fill = "gray") +
geom_density(color = "red") +
facet_wrap(~ Strategy, scales = "free_y") +
xlab("Net Monetary Benefit (NMB) x10^3") +
scale_x_continuous(breaks = number_ticks(5), labels = dollar) +
scale_y_continuous(breaks = number_ticks(5)) +
theme_bw()
#### Incremental NMB (INMB) ####
# Calculate INMB of B vs A
# Only B vs A but we could have plotted all combinations
inmb <- data.frame(Simulation = 1:n.sim,
`Strategy B vs Strategy A` = nmb$`Strategy B` - nmb$`Strategy A`)
## Format data frame suitably for plotting
inmb.gg <- melt(inmb, id.vars = "Simulation",
variable.name = "Comparison",
value.name = "INMB")
txtsize<-16
## Plot INMB
ggplot(inmb.gg, aes(x = INMB/1000)) +
geom_histogram(aes(y =..density..), col="black", fill = "gray") +
geom_density(color = "red") +
geom_vline(xintercept = 0, col = 4, size = 1.5, linetype = "dashed") +
facet_wrap(~ Comparison, scales = "free_y") +
xlab("Incremental Net Monetary Benefit (INMB) in thousand $") +
scale_x_continuous(breaks = number_ticks(5), limits = c(-100, 100)) +
scale_y_continuous(breaks = number_ticks(5)) +
theme_bw(base_size = 14)
#### Loss Matrix ####
# Find optimal strategy (d*) based on the highest expected NMB
d.star <- which.max(colMeans(nmb))
d.star
## Compute Loss matrix iterating over all strategies
# Initialize loss matrix of dimension: number of simulation by number of strategies
loss <- matrix(0, n.sim, n.strategies)
for (d in 1:n.strategies){ # d <- 1
loss[, d] <- nmb[, d] - nmb[, d.star]
}
head(loss)
# Or without iterating (much faster!)
loss <- as.matrix(nmb - nmb[, d.star])
head(loss)
#### EVPI ####
## Find maximum loss overall strategies at each state of the world
## (i.e., PSA sample)
max.loss.i <- rowMaxs(loss)
head(max.loss.i)
## Average across all states of the world
evpi <- mean(max.loss.i)
evpi
#### EVPPI ####
names.params <- c("Mean No. Visits (A)",
"Mean No. Visits (B)",
"Prob. Failing (A)",
"Prob. Failing (B)")
# Matrix with parameters
x <- toy[, 1:4]
colnames(x) <- names.params
head(x)
# Number and names of parameters
n.params <- ncol(x)
n.params
# name.params <- colnames(x)
# name.params
### Histogram of parameters
# Format data suitably for plotting
params <- melt(x, variable.name = "Parameter")
head(params)
# Make parameter names as factors (helps with plotting formatting)
params$Parameter <- factor(params$Parameter,
levels = names.params,
labels = names.params)
# Facet plot of parameter distributions
ggplot(params, aes(x = value)) +
geom_histogram(aes(y =..density..), col="black", fill = "gray") +
geom_density(color = "red") +
facet_wrap(~ Parameter, scales = "free") +
scale_x_continuous(breaks = number_ticks(5)) +
scale_y_continuous(breaks = number_ticks(5)) +
theme_bw(base_size = 14)
### Construct Spline metamodel
### Splines
## Initialize EVPPI vector
evppi.splines <- matrix(0, n.params)
lmm1 <- vector("list", n.params)
lmm2 <- vector("list", n.params)
lmm3 <- vector("list", n.params)
for (p in 1:n.params){ # p <- 1
print(paste("Computing EVPPI of parameter", names.params[p]))
# Estimate Splines
lmm1[[p]] <- gam(loss[, 1] ~ s(x[, p]))
lmm2[[p]] <- gam(loss[, 2] ~ s(x[, p]))
lmm3[[p]] <- gam(loss[, 2] ~ s(x[, p]))
# Predict Loss using Splines
Lhat.splines <- cbind(lmm1[[p]]$fitted, lmm2[[p]]$fitted, lmm3[[p]]$fitted)
# Compute EVPPI
evppi.splines[p] <- mean(rowMaxs(Lhat.splines))
}
### Ploting EVPPI using of order polynomial
evppi.splines.gg <- data.frame(Parameter = names.params, EVPPI = evppi.splines)
evppi.splines.gg$Parameter <- factor((evppi.splines.gg$Parameter),
levels = names.params[order(evppi.splines.gg$EVPPI, decreasing = TRUE)])
# Plot EVPPI using ggplot2 package
ggplot(data = evppi.splines.gg, aes(x = Parameter, y = EVPPI)) +
geom_bar(stat = "identity") +
ylab("EVPPI ($)") +
scale_y_continuous(breaks = number_ticks(6), labels = comma) +
theme_bw(base_size = 14)
#### EVSI ####
# Effective (prior) Sample size
n0 <- c(10, # MeanNumVisitsA
10, # MeanNumVisitsB
10, # ProbFailA
10) # ProbFailB
n <- c(0, 1, 5, 10, seq(20, 200, by = 20))
n.samples <- length(n)
### Each parameter individually (only assuming linear relationship)
# Initialize EVSI matrix for each parameters
evsi <- data.frame(N = n, matrix(0, nrow = n.samples, ncol = n.params))
# Name columns of EVPSI matrix with parameter names
colnames(evsi)[-1] <- names.params
# Compute EVSI for all parameters separately
for (p in 1:n.params){ # p <- 1
print(paste("Computing EVSI of parameter", names.params[p]))
# Update loss based on gaussian approximation for each sample of interest
for (nSamp in 1:n.samples){ # nSamp <- 10
Ltilde1 <- predict.ga(lmm1[[p]], n = n[nSamp], n0 = n0[p])
Ltilde2 <- predict.ga(lmm2[[p]], n = n[nSamp], n0 = n0[p])
Ltilde3 <- predict.ga(lmm3[[p]], n = n[nSamp], n0 = n0[p])
## Combine losses into one matrix
Ltilde <- cbind(Ltilde1, Ltilde2, Ltilde3)
### Apply EVSI equation
evsi[nSamp, p+1] <- mean(rowMaxs(Ltilde))
}
}
evsi
### Plotting EVSI
# Create EVSI data frame for plotting in decreasing order of EVPPI
evsi.gg <- melt(evsi[1:21,], id.vars = "N",
variable.name = "Parameter",
value.name = "evsi")
evsi
evsi[1:21,]
### Plotting EVSI
# Create EVSI data frame for plotting in decreasing order of EVPPI
evsi.gg <- melt(evsi[1:21,], id.vars = "N",
variable.name = "Parameter",
value.name = "evsi")
evsi.gg
evsi.gg
# Plot evsi using ggplot2 package
ggplot(evsi_gg, aes(x = N, y = evsi)) +  # colour = Parameter
geom_line() +
geom_point() +
facet_wrap(~ Parameter) +  # scales = "free_y"
ggtitle("Expected Value of Sample Information (EVSI)") +
xlab("Sample size (n)") +
ylab("$") +
scale_x_continuous(breaks = number_ticks(5)) +
scale_y_continuous(breaks = number_ticks(6), labels = dollar) +
theme_bw(base_size = 14)
evsi_gg$Parameter <- factor((evsi_gg$Parameter),
levels = names_params[order(evppi_splines_gg$EVPPI, decreasing = TRUE)])
# Plotting EVSI
# Create EVSI data frame for plotting in decreasing order of EVPPI
evsi_gg <- melt(evsi[1:21,], id.vars = "N",
variable.name = "Parameter",
value.name = "evsi")
evsi_gg
# Plotting EVSI
# Create EVSI data frame for plotting in decreasing order of EVPPI
evsi_gg <- melt(evsi[1:21,], id.vars = "N",
variable.name = "Parameter",
value.name = "evsi")
evsi_gg$Parameter <- factor((evsi_gg$Parameter),
levels = names_params[order(evppi_splines_gg$EVPPI, decreasing = TRUE)])
install.packages("gdata")
install.packages(c("lhs", "plotrix", "psych"))
