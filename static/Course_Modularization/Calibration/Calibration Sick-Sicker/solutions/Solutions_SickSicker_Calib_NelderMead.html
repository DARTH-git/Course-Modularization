---
title: 'Calibrating the Sick-Sicker model'
subtitle: 'Directed search using Nelder-mead'
author: "The DARTH workgroup"
output:
  pdf_document: default
  html_document: default
---

<link href="/rmarkdown-libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="/rmarkdown-libs/anchor-sections/anchor-sections.js"></script>


<p>Developed by the Decision Analysis in R for Technologies in Health (DARTH) workgroup:</p>
<p>Fernando Alarid-Escudero, PhD (1)</p>
<p>Eva A. Enns, MS, PhD (2)</p>
<p>M.G. Myriam Hunink, MD, PhD (3,4)</p>
<p>Hawre J. Jalal, MD, PhD (5)</p>
<p>Eline M. Krijkamp, MSc (3)</p>
<p>Petros Pechlivanoglou, PhD (6)</p>
<p>Alan Yang, MSc (7)</p>
<p>In collaboration of:</p>
<ol style="list-style-type: decimal">
<li>Drug Policy Program, Center for Research and Teaching in Economics (CIDE) - CONACyT,
Aguascalientes, Mexico</li>
<li>University of Minnesota School of Public Health, Minneapolis, MN, USA</li>
<li>Erasmus MC, Rotterdam, The Netherlands</li>
<li>Harvard T.H. Chan School of Public Health, Boston, USA</li>
<li>University of Pittsburgh Graduate School of Public Health, Pittsburgh, PA, USA</li>
<li>The Hospital for Sick Children, Toronto and University of Toronto, Toronto ON, Canada</li>
<li>The Hospital for Sick Children, Toronto ON, Canada</li>
</ol>
<p>Please cite our publications when using this code:</p>
<ul>
<li><p>Alarid-Escudero F, Maclehose RF, Peralta Y, Kuntz KM, Enns EA.
Non-identifiability in model calibration and implications for
medical decision making. Med Decis Making. 2018; 38(7):810-821.</p></li>
<li><p>Jalal H, Pechlivanoglou P, Krijkamp E, Alarid-Escudero F, Enns E, Hunink MG.
An Overview of R in Health Decision Sciences. Med Decis Making. 2017; 37(3): 735-746.
<a href="https://journals.sagepub.com/doi/abs/10.1177/0272989X16686559" class="uri">https://journals.sagepub.com/doi/abs/10.1177/0272989X16686559</a></p></li>
</ul>
<p>A walkthrough of the code could be found in the follwing link:
- <a href="https://darth-git.github.io/calibSMDM2018-materials/" class="uri">https://darth-git.github.io/calibSMDM2018-materials/</a></p>
<p>Copyright 2017, THE HOSPITAL FOR SICK CHILDREN AND THE COLLABORATING INSTITUTIONS.
All rights reserved in Canada, the United States and worldwide. Copyright,
trademarks, trade names and any and all associated intellectual property are
exclusively owned by THE HOSPITAL FOR Sick CHILDREN and the collaborating
institutions. These materials may be used, reproduced, modified, distributed
and adapted with proper attribution.</p>
<div style="page-break-after: always;"></div>
<p>Change <code>eval</code> to <code>TRUE</code> if you want to knit this document.</p>
<pre class="r"><code>rm(list = ls())      # clear memory (removes all the variables from the workspace)</code></pre>
<div id="calibration-specifications" class="section level1">
<h1>00 Calibration Specifications</h1>
<p>Model: Sick-Sicker 4-state Markov Model</p>
<p>Inputs to be calibrated: p_S1S2, hr_S1, hr_S2</p>
<p>Targets: Surv, Prev, PropSick</p>
<p>Calibration method: Directed search using Nelder-mead</p>
<p>Goodness-of-fit measure: Sum of Log-Likelihood</p>
</div>
<div id="load-packages" class="section level1">
<h1>01 Load packages</h1>
<pre class="r"><code>if (!require(&#39;pacman&#39;)) install.packages(&#39;pacman&#39;); library(pacman) # use this package to conveniently install other packages
# load (install if required) packages from CRAN
p_load(&quot;lhs&quot;, &quot;plotrix&quot;, &quot;psych&quot;, &quot;scatterplot3d&quot;)  
# install_github(&quot;DARTH-git/darthtools&quot;, force = TRUE) Uncomment if there is a newer version
p_load_gh(&quot;DARTH-git/darthtools&quot;)</code></pre>
</div>
<div id="load-target-data" class="section level1">
<h1>02 Load target data</h1>
<pre class="r"><code>load(&quot;SickSicker_CalibTargets.RData&quot;)
lst_targets &lt;- SickSicker_targets

# Plot the targets

# TARGET 1: Survival (&quot;Surv&quot;)
plotrix::plotCI(x = lst_targets$Surv$time, y = lst_targets$Surv$value, 
                ui = lst_targets$Surv$ub,
                li = lst_targets$Surv$lb,
                ylim = c(0, 1), 
                xlab = &quot;Time&quot;, ylab = &quot;Pr Survive&quot;)

# TARGET 2: Prevalence (&quot;Prev&quot;)
plotrix::plotCI(x = lst_targets$Prev$time, y = lst_targets$Prev$value,
                ui = lst_targets$Prev$ub,
                li = lst_targets$Prev$lb,
                ylim = c(0, 1),
                xlab = &quot;Time&quot;, ylab = &quot;Prev&quot;)

# TARGET 3: Proportion who are Sick (&quot;PropSick&quot;), among all those afflicted (Sick+Sicker)
plotrix::plotCI(x = lst_targets$PropSick$time, y = lst_targets$PropSick$value,
                ui = lst_targets$PropSick$ub,
                li = lst_targets$PropSick$lb,
                ylim = c(0, 1),
                xlab = &quot;Time&quot;, ylab = &quot;PropSick&quot;)</code></pre>
</div>
<div id="load-model-as-a-function" class="section level1">
<h1>03 Load model as a function</h1>
<pre class="r"><code># - inputs are parameters to be estimated through calibration
# - outputs correspond to the target data

# creates the function run_sick_sicker_markov()
source(&quot;SickSicker_MarkovModel_Function.R&quot;)

# Check that it works
v_params_test &lt;- c(p_S1S2 = 0.105, hr_S1 = 3, hr_S2 = 10)
run_sick_sicker_markov(v_params_test) # It works!</code></pre>
</div>
<div id="specify-calibration-parameters" class="section level1">
<h1>04 Specify calibration parameters</h1>
<pre class="r"><code># Specify seed (for reproducible sequence of random numbers)
set.seed(072218)

# number of initial starting points
n_init &lt;- 100

# names and number of input parameters to be calibrated
v_param_names &lt;- c(&quot;p_S1S2&quot;,&quot;hr_S1&quot;,&quot;hr_S2&quot;)
n_param &lt;- length(v_param_names)

# range on input search space
lb &lt;- c(p_S1S2 = 0.01, hr_S1 = 1.0, hr_S2 = 5) # lower bound
ub &lt;- c(p_S1S2 = 0.50, hr_S1 = 4.5, hr_S2 = 15) # upper bound

# number of calibration targets
v_target_names &lt;- c(&quot;Surv&quot;, &quot;Prev&quot;, &quot;PropSick&quot;)
n_target &lt;- length(v_target_names)</code></pre>
</div>
<div id="calibration-functions" class="section level1">
<h1>05 Calibration functions</h1>
<pre class="r"><code># Write goodness-of-fit function to pass to Nelder-Mead algorithm
f_gof &lt;- function(v_params){
  
  # Run model for parametr set &quot;v_params&quot;
  model_res &lt;- run_sick_sicker_markov(v_params)
  
  # Calculate goodness-of-fit of model outputs to targets
  v_GOF &lt;- numeric(n_target)
  # TARGET 1: Survival (&quot;Surv&quot;)
  # log likelihood  
  v_GOF[1] &lt;- sum(dnorm(x = lst_targets$Surv$value,
                        mean = model_res$Surv,
                        sd = lst_targets$Surv$se,
                        log = T))
  
  # TARGET 2: &quot;Prev&quot;
  # log likelihood
  v_GOF[2] &lt;- sum(dnorm(x = lst_targets$Prev$value,
                        mean = model_res$Prev,
                        sd = lst_targets$Prev$se,
                        log = T))
  
  # TARGET 3: &quot;PropSick&quot;
  # log likelihood
  v_GOF[3] &lt;- sum(dnorm(x = lst_targets$PropSick$value,
                        mean = model_res$PropSick,
                        sd = lst_targets$PropSick$se,
                        log = T))
  
  # OVERALL
  # can give different targets different weights
  v_weights &lt;- rep(1,n_target)
  # weighted sum
  GOF_overall &lt;- sum(v_GOF[1:n_target] * v_weights)
  
  # return GOF
  return(GOF_overall)
}</code></pre>
</div>
<div id="calibrate" class="section level1">
<h1>06 Calibrate!</h1>
<pre class="r"><code># record start time of calibration
t_init &lt;- Sys.time()

###  Sample multiple random starting values for Nelder-Mead  ###
v_params_init &lt;- matrix(nrow=n_init,ncol=n_param)
for (i in 1:n_param){
  v_params_init[,i] &lt;- runif(n_init,min=lb[i],max=ub[i])
}
colnames(v_params_init) &lt;- v_param_names

###  Run Nelder-Mead for each starting point  ###
m_calib_res &lt;- matrix(nrow = n_init, ncol = n_param+1)
colnames(m_calib_res) &lt;- c(v_param_names, &quot;Overall_fit&quot;)
for (j in 1:n_init){
  
  ### use optim() as Nelder-Mead ###
  fit_nm &lt;- optim(v_params_init[j,], f_gof,
                 control = list(fnscale = -1, # switches from minimization to maximization
                                maxit = 1000), hessian = T)
  m_calib_res[j,] &lt;- c(fit_nm$par,fit_nm$value)
  
  ### to use a simulated annealing instead ###
  # fit_sa &lt;- optim(v_params_init[j,], f_gof,
  #                method = c(&quot;SANN&quot;),  # switches to using simulated annealing
  #                control = list(temp = 10, tmax = 10, # algorithm tuning parameters
  #                               fnscale = -1, maxit = 1000),
  #                hessian = T)
  # m_calib_res[j,] = c(fit_sa$par,fit_sa$value)
  
  ### to use a genetic algorithm instead ###
  # library(DEoptim)
  # f_fitness &lt;- function(params){
  #   names(params) = v_param_names
  #   return(-f_gof(params))}
  # fit_ga = DEoptim(f_fitness, lower=lb, upper=ub)
  # m_calib_res[j,] = c(fit_ga$optim$bestmem,-1*fit_ga$optim$bestval)
  
}

# Calculate computation time
comp_time &lt;- Sys.time() - t_init</code></pre>
</div>
<div id="exploring-best-fitting-input-sets" class="section level1">
<h1>07 Exploring best-fitting input sets</h1>
<pre class="r"><code># Arrange parameter sets in order of fit
m_calib_res &lt;- m_calib_res[order(-m_calib_res[,&quot;Overall_fit&quot;]),]

# Examine the top 10 best-fitting sets
m_calib_res[1:10,]

# Plot the top 10 (top 10%)
scatterplot3d(x = m_calib_res[1:10, 1],
              y = m_calib_res[1:10, 2],
              z = m_calib_res[1:10, 3],
              xlim = c(lb[1],ub[1]), ylim = c(lb[2],ub[2]), zlim = c(lb[3],ub[3]),
              xlab = v_param_names[1], ylab = v_param_names[2], zlab = v_param_names[3])

# Pairwise comparison of top 10 sets
pairs.panels(m_calib_res[1:10,v_param_names])

### Plot model-predicted output at best set vs targets ###
v_out_best &lt;- run_sick_sicker_markov(m_calib_res[1,])

# TARGET 1: Survival (&quot;Surv&quot;)
plotrix::plotCI(x = lst_targets$Surv$time, y = lst_targets$Surv$value, 
                ui = lst_targets$Surv$ub,
                li = lst_targets$Surv$lb,
                ylim = c(0, 1), 
                xlab = &quot;Time&quot;, ylab = &quot;Pr Survive&quot;)
points(x = lst_targets$Surv$time, 
       y = v_out_best$Surv, 
       pch = 8, col = &quot;red&quot;)
legend(&quot;topright&quot;, 
       legend = c(&quot;Target&quot;, &quot;Model-predicted output&quot;),
       col = c(&quot;black&quot;, &quot;red&quot;), pch = c(1, 8))

# TARGET 2: &quot;Prev&quot;
plotrix::plotCI(x = lst_targets$Prev$time, y = lst_targets$Prev$value,
                ui = lst_targets$Prev$ub,
                li = lst_targets$Prev$lb,
                ylim = c(0, 1),
                xlab = &quot;Time&quot;, ylab = &quot;Prev&quot;)
points(x = lst_targets$Prev$time,
       y = v_out_best$Prev,
       pch = 8, col = &quot;red&quot;)
legend(&quot;topright&quot;,
       legend = c(&quot;Target&quot;, &quot;Model-predicted output&quot;),
       col = c(&quot;black&quot;, &quot;red&quot;), pch = c(1, 8))

# TARGET 3: &quot;PropSick&quot;
plotrix::plotCI(x = lst_targets$PropSick$time, y = lst_targets$PropSick$value,
                ui = lst_targets$PropSick$ub,
                li = lst_targets$PropSick$lb,
                ylim = c(0, 1),
                xlab = &quot;Time&quot;, ylab = &quot;PropSick&quot;)
points(x = lst_targets$PropSick$time,
       y = v_out_best$PropSick,
       pch = 8, col = &quot;red&quot;)
legend(&quot;topright&quot;,
       legend = c(&quot;Target&quot;, &quot;Model-predicted output&quot;),
       col = c(&quot;black&quot;, &quot;red&quot;), pch = c(1, 8))</code></pre>
</div>
